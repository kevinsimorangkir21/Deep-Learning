{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 Deep Learning - Meeting 2\n",
    "\n",
    "### Topics\n",
    "Feedforward Neural Network\n",
    "\n",
    "### Purposes\n",
    "- Mahasiswa mampu memahami konsep metode Backpropagation Neural Network.\n",
    "- Mahasiswa mampu menerapkan perhitungan matematika Backpropagation Neural Network dan menerapkan \n",
    "  pemrograman hitungannya menggunakan Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inisiasi nilai W dan Bias. Pada gambar 2 dapat dilihat bahwa nilai W dan Bias dinisiasi di\n",
    "dalam class NeuralNetwork. Pada gambar nilai untuk W dari input ke hidden adalah\n",
    "matrix 2x3, dan matrix untuk W dari hidden ke output yaitu 3 x 2. Pada gambar juga dapat\n",
    "dilihat nilai bias untuk hiden layer dan output layer sudah diinisiasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mendefinisikan class neural network\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # menginisialisasi bobot dari input ke hidden\n",
    "        self.weights_input_hidden = np.array([[0.5, 0.2, -0.3],\n",
    "                                              [0.7, -0.4, 0.6]])\n",
    "\n",
    "        # menginisialisasi bobot dari hidden ke output\n",
    "        self.weights_hidden_output = np.array([[0.1, -0.2],\n",
    "                                               [0.4, 0.3],\n",
    "                                               [-0.5, 0.7]])\n",
    "\n",
    "        # menginisialisasi bias\n",
    "        self.bias_hidden = np.array([0.5, 0.5, 0.5])  # Bias untuk hidden\n",
    "        self.bias_output = np.array([0.5, -0.5])      # Bias untuk output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah melakukan inisiasi selanjutnya adalah membuat sebuh fungsi forward (fungsi maju\n",
    "untuk mendapatkan nilai prediksi nya). Potongan kode dapat dilihat pada gambar 3. Fungsi\n",
    "forward masih berada dalam class NeuralNetwork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, inputs):\n",
    "    # Forward propagation\n",
    "    self.hidden_input = np.dot(\n",
    "        inputs, self.weights_input_hidden) + self.bias_hidden\n",
    "    self.hidden_output = sigmoid(self.hidden_input)\n",
    "    self.output_input = np.dot(\n",
    "        self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
    "    self.predicted_output = sigmoid(self.output_input)\n",
    "    return self.predicted_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil dari fungsi forward yaitu nilai prediksi akan digunakan di dalam fungsi backward. Fungsi backwar masih berada di dalam class NeuralNetwork. Potongan kode untuk fungsi backward dapat dilihat pada gambar 4. Pada gambar tiga dapat dilihat ada proses perhitungan error (dapat dilihat pada baris ke 36 dan 37). Perhitungan error tersebut masih terhadap output saja. Pada gambar 4, dapat dilihat juga ada proses mengupdate nilai dari W, nilai W diupdate berdasarkan proses yang terjadi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, inputs, target, learning_rate):\n",
    "    # Backpropagation\n",
    "    error = target - self.predicted_output\n",
    "    delta_output = error * sigmoid_derivative(self.predicted_output)\n",
    "\n",
    "    error_hidden = delta_output.dot(self.weights_hidden_output.T)\n",
    "    delta_hidden = error_hidden * sigmoid_derivative(self.hidden_output)\n",
    "\n",
    "    # Update weights\n",
    "    self.weights_hidden_output += np.outer(\n",
    "        self.hidden_output, delta_output) * learning_rate\n",
    "    self.weights_input_hidden += np.outer(inputs, delta_hidden) * learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masih di class yang sama yaitu class Neural Network, terdapat suatu fungsi yang diberi nama train. Fungs train mencakup perhitungan output (forward propagation, update bobot (backward propagation)) dan melihat total error yang terjadi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, training_data, targets, epochs, learning_rate):\n",
    "    for epoch in range(epochs):\n",
    "        total_error = 0  # Initialize total error for the epoch\n",
    "        for i in range(len(training_data)):\n",
    "            inputs = training_data[i]\n",
    "            target = targets[i]\n",
    "\n",
    "            self.forward(inputs)\n",
    "            self.backward(inputs, target, learning_rate)\n",
    "\n",
    "            # Squared Error\n",
    "            total_error += np.mean(np.square(target - self.predicted_output))\n",
    "\n",
    "        # Print error setiap 100 iterasi aja\n",
    "        if epoch % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch}, Average Error: {total_error / len(training_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jangan lupa untuk menambahkan sebuah fungsi untuk memanggil fungsi forward pada input, di dalam class NeuralNetwork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, data):\n",
    "    return self.forward(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terakhir panggil class NeuralNetwork. Potongan kode dapa dilihat pada gambar 7. Pada gambar terdapat input_size dengan nilai 2, artinya terdapat 2 input yaitu x1 dan x2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NeuralNetwork' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     15\u001b[0m nn \u001b[38;5;241m=\u001b[39m NeuralNetwork(input_size, hidden_size, output_size)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m(training_data, targets, epochs, learning_rate)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Test network\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs \u001b[38;5;129;01min\u001b[39;00m training_data:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NeuralNetwork' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Input atau nilai x nya.\n",
    "training_data = np.array([[0, 5]])\n",
    "\n",
    "targets = np.array([0])\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 3\n",
    "output_size = 1\n",
    "learning_rate = 0.1\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "\n",
    "nn.train(training_data, targets, epochs, learning_rate)\n",
    "\n",
    "# Test network\n",
    "for inputs in training_data:\n",
    "    prediction = nn.predict(inputs)\n",
    "    print(f\"Input: {inputs}, Predicted Output: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambahan: tambahakan fungsi aktivasi, yang digunakan. Fungsi aktivasi terletak diluar class NeuralNetwork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi aktivasi yang akan dipanggil\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
